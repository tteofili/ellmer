{
  "data": [
    {
      "id": 0,
      "ltuple": {
        "ltable_name": "citrus",
        "ltable_addr": "' 6703 melrose ave. '",
        "ltable_city": "` los angeles '",
        "ltable_phone": "213/857 -0034",
        "ltable_res_type": "californian",
        "ltable_class": "6.0"
      },
      "rtuple": {
        "rtable_name": "` le chardonnay ( los angeles ) '",
        "rtable_addr": "' 8284 melrose ave. '",
        "rtable_city": "` los angeles '",
        "rtable_phone": "213-655-8880",
        "rtable_res_type": "` french bistro '",
        "rtable_class": "12.0"
      },
      "prediction": 1,
      "label": 0,
      "saliency": {},
      "cfs": [
        {}
      ],
      "latency": 13.654319763183594,
      "conversation": [
        [
          "system",
          "You are an expert assistant for Entity Resolution tasks."
        ],
        [
          "user",
          "Given a pair of records, return \"yes\" if the records match or \"no\" if they don't. Your answer will be one of \"yes\", \"no\"."
        ],
        [
          "assistant",
          "Ok, I will reply with just \"yes\" or \"no\", now give me the two records."
        ],
        [
          "user",
          "record1:\n{ltuple}\n record2:\n{rtuple}\n"
        ],
        [
          "assistant",
          "  Yes, the records match."
        ],
        [
          "user",
          "A {feature}-level saliency explanation highlights the most relevant {feature}s of the input data that contributed the most to your decision on the above prediction. In a {feature}-level saliency explanation, a saliency score is attached to each {feature}. It aids in understanding which {feature}s you paid attention to the most during your decision-making process."
        ],
        [
          "assistant",
          "Ok, I can generate a {feature}-level saliency explanation as a dictionary where each {feature} is a key having its saliency score as value."
        ],
        [
          "user",
          "Return a saliency explanation for the above prediction in JSON format."
        ],
        [
          "assistant",
          "{{}}"
        ],
        [
          "user",
          "A {feature}-level counterfactual explanation consists of an altered input with one or more key {feature}s of the input data changed, such that your prediction flips."
        ],
        [
          "assistant",
          "Ok, I can generate a feature-level counterfactual explanation in the form of a single JSON containing two records, having a column for each input attribute containing its counterfactual value."
        ],
        [
          "user",
          "Return a counterfactual explanation for the above prediction in JSON format."
        ],
        [
          "assistant",
          "{}"
        ]
      ]
    },
    {
      "id": 1,
      "ltuple": {
        "ltable_name": "` yujean kang \\ 's gourmet chinese cuisine '",
        "ltable_addr": "'67 n. raymond ave. '",
        "ltable_city": "` los angeles '",
        "ltable_phone": "818/585 -0855",
        "ltable_res_type": "asian",
        "ltable_class": "22.0"
      },
      "rtuple": {
        "rtable_name": "` yujean kang \\ 's '",
        "rtable_addr": "'67 n. raymond ave. '",
        "rtable_city": "pasadena",
        "rtable_phone": "818-585-0855",
        "rtable_res_type": "chinese",
        "rtable_class": "22.0"
      },
      "prediction": 1,
      "label": 1,
      "saliency": {},
      "cfs": [
        {}
      ],
      "latency": 13.30735731124878,
      "conversation": [
        [
          "system",
          "You are an expert assistant for Entity Resolution tasks."
        ],
        [
          "user",
          "Given a pair of records, return \"yes\" if the records match or \"no\" if they don't. Your answer will be one of \"yes\", \"no\"."
        ],
        [
          "assistant",
          "Ok, I will reply with just \"yes\" or \"no\", now give me the two records."
        ],
        [
          "user",
          "record1:\n{ltuple}\n record2:\n{rtuple}\n"
        ],
        [
          "assistant",
          "  Yes, the records match."
        ],
        [
          "user",
          "A {feature}-level saliency explanation highlights the most relevant {feature}s of the input data that contributed the most to your decision on the above prediction. In a {feature}-level saliency explanation, a saliency score is attached to each {feature}. It aids in understanding which {feature}s you paid attention to the most during your decision-making process."
        ],
        [
          "assistant",
          "Ok, I can generate a {feature}-level saliency explanation as a dictionary where each {feature} is a key having its saliency score as value."
        ],
        [
          "user",
          "Return a saliency explanation for the above prediction in JSON format."
        ],
        [
          "assistant",
          "{{}}"
        ],
        [
          "user",
          "A {feature}-level counterfactual explanation consists of an altered input with one or more key {feature}s of the input data changed, such that your prediction flips."
        ],
        [
          "assistant",
          "Ok, I can generate a feature-level counterfactual explanation in the form of a single JSON containing two records, having a column for each input attribute containing its counterfactual value."
        ],
        [
          "user",
          "Return a counterfactual explanation for the above prediction in JSON format."
        ],
        [
          "assistant",
          "{}"
        ]
      ]
    },
    {
      "id": 2,
      "ltuple": {
        "ltable_name": "oritalia",
        "ltable_addr": "' 1915 fillmore st. '",
        "ltable_city": "` san francisco '",
        "ltable_phone": "415/346 -1333",
        "ltable_res_type": "italian",
        "ltable_class": "501.0"
      },
      "rtuple": {
        "rtable_name": "` trio cafe '",
        "rtable_addr": "' 1870 fillmore st. '",
        "rtable_city": "` san francisco '",
        "rtable_phone": "415-563-2248",
        "rtable_res_type": "american",
        "rtable_class": "749.0"
      },
      "prediction": 1,
      "label": 0,
      "saliency": {},
      "cfs": [
        {}
      ],
      "latency": 14.858509063720703,
      "conversation": [
        [
          "system",
          "You are an expert assistant for Entity Resolution tasks."
        ],
        [
          "user",
          "Given a pair of records, return \"yes\" if the records match or \"no\" if they don't. Your answer will be one of \"yes\", \"no\"."
        ],
        [
          "assistant",
          "Ok, I will reply with just \"yes\" or \"no\", now give me the two records."
        ],
        [
          "user",
          "record1:\n{ltuple}\n record2:\n{rtuple}\n"
        ],
        [
          "assistant",
          "  Yes, the records match."
        ],
        [
          "user",
          "A {feature}-level saliency explanation highlights the most relevant {feature}s of the input data that contributed the most to your decision on the above prediction. In a {feature}-level saliency explanation, a saliency score is attached to each {feature}. It aids in understanding which {feature}s you paid attention to the most during your decision-making process."
        ],
        [
          "assistant",
          "Ok, I can generate a {feature}-level saliency explanation as a dictionary where each {feature} is a key having its saliency score as value."
        ],
        [
          "user",
          "Return a saliency explanation for the above prediction in JSON format."
        ],
        [
          "assistant",
          "{{}}"
        ],
        [
          "user",
          "A {feature}-level counterfactual explanation consists of an altered input with one or more key {feature}s of the input data changed, such that your prediction flips."
        ],
        [
          "assistant",
          "Ok, I can generate a feature-level counterfactual explanation in the form of a single JSON containing two records, having a column for each input attribute containing its counterfactual value."
        ],
        [
          "user",
          "Return a counterfactual explanation for the above prediction in JSON format."
        ],
        [
          "assistant",
          "{}"
        ]
      ]
    }
  ],
  "total_time": 41.83110308647156,
  "metrics": {
    "faithfulness": {
      "ptse_sample": 0.4
    },
    "counterfactual_metrics": {
      "ptse_sample": {
        "validity": 0.0,
        "proximity": 0.0,
        "sparsity": 0.0,
        "diversity": 0.0
      }
    }
  },
  "tokens": 973.3333333333334,
  "predictions": 8.0
}